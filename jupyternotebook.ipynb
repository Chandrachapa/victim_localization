{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e119d389-37a0-4cdf-a8eb-1f8fb88f5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codac import *\n",
    "import math\n",
    "import sys # only for checking if this example still works\n",
    "\n",
    "\n",
    "# =================== 0. Parameters, truth and data ====================\n",
    "\n",
    "# Truth (unknown pose)\n",
    "x_truth = [0,0,math.pi/6] # (x,y,heading)\n",
    "\n",
    "# Creating random map of landmarks\n",
    "map_area = IntervalVector(2, [-8,8])\n",
    "v_map = DataLoader.generate_landmarks_boxes(map_area, nb_landmarks = 1)\n",
    "\n",
    "# The following function generates a set of [range]x[bearing] values\n",
    "v_obs = DataLoader.generate_static_observations(x_truth, v_map, False)\n",
    "\n",
    "# Adding uncertainties on the measurements\n",
    "for y in v_obs: # for each observation:\n",
    "  y[0].inflate(0.3) # range\n",
    "  y[1].inflate(0.1) # bearing\n",
    "\n",
    "\n",
    "# =============== 1. Defining domains for our variables ================\n",
    "\n",
    "x = IntervalVector(2) # unknown position\n",
    "heading = Interval(x_truth[2]).inflate(0.01) # measured heading\n",
    "\n",
    "\n",
    "# =========== 2. Defining contractors to deal with equations ===========\n",
    "\n",
    "ctc_plus = CtcFunction(Function(\"a\", \"b\", \"c\", \"a+b-c\")) # a+b=c\n",
    "ctc_minus = CtcFunction(Function(\"a\", \"b\", \"c\", \"a-b-c\")) # a-b=c\n",
    "# We also use the predefined contractor ctc::polar, no need to build it\n",
    "\n",
    "\n",
    "# =============== 3. Adding the contractors to a network ===============\n",
    "\n",
    "cn = ContractorNetwork()\n",
    "\n",
    "for i in range(0,len(v_obs)):\n",
    "\n",
    "  # Intermediate variables\n",
    "  alpha = cn.create_interm_var(Interval())\n",
    "  d = cn.create_interm_var(IntervalVector(2))\n",
    "\n",
    "  cn.add(ctc_plus, [v_obs[i][1], heading, alpha])\n",
    "  cn.add(ctc_minus, [v_map[i], x, d])\n",
    "  cn.add(ctc.polar, [d, v_obs[i][0], alpha])\n",
    "\n",
    "\n",
    "# ======================= 4. Solving the problem =======================\n",
    "\n",
    "cn.contract()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99f535-b6c5-43d2-b5ab-f89f62ac1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 1\n",
      "routinely update 93\n",
      "here 1\n",
      "routinely update 599\n",
      "here 1\n",
      "routinely update 1969\n",
      "here 1\n",
      "routinely update 2560\n",
      "here 1\n",
      "routinely update 3897\n",
      "here 1\n",
      "routinely update 5956\n",
      "here 1\n",
      "routinely update 6758\n",
      "here 1\n",
      "routinely update 6784\n",
      "here 1\n"
     ]
    }
   ],
   "source": [
    "#rssi mcl code \n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "#montecarlo\n",
    "#ord\n",
    "#last update: sep 17\n",
    "\n",
    "from codac import *\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# =================== 0. Import data =========================================================================================================================================================\n",
    "df = pd. read_excel (r'csp_3gnbs.xlsx', sheet_name='Input')\n",
    "rows = df.shape[0]\n",
    "columns = df.shape[1]\n",
    "random.seed(100)\n",
    "outdoor_los=False\n",
    "outdoor_nlos=False\n",
    "indoor_nlos= True\n",
    "no_aoa = True\n",
    "toa_availability = False \n",
    "\n",
    "# =================== 0. Parameters, truth and data ==========================================================================================================================================\n",
    "iteration_dt = 2#time for solving csp problem(sec)\n",
    "benchmark_truth,benchmark_est, update_count,dist_arr = [],[],[],[]\n",
    "all_er_mean,all_est_coor, all_pix_coor , all_contract_time,time_arr ,id_time_arr = [],[],[],[],[],[]\n",
    "xgps_all,ygps_all,all_x_gps,all_gps_radius ={},{},{},{}\n",
    "node_incoverage , time_contract,id_contract={},{},{}\n",
    "past_bench_ids,id_arr,time_carr = [],[], []\n",
    "id_error,id_update,id_updategsp={},{},{}\n",
    "id_time_error,err_minmax,error_count={},{},{}\n",
    "time_error,id_count,sol_ids  ={},{},{}\n",
    "time_complexity,node_heading,node_xtruth={},{},{}\n",
    "nodearr,emergarr,sol = [],[],[]\n",
    "node_benchids,node_benchtruth,all_x_gpstheta={},{},{}\n",
    "id_time_cdt,id_time_est_coord={},{}\n",
    "bench_heading ,btruth, ntruth,ntruthaoa={},{}, {},{}\n",
    "\n",
    "#initial gps estimate of each benchmark node \n",
    "#def gps_estimate(starting_row, last_row):\n",
    "for i in range(1,rows):\n",
    "    emerg_ids = df.loc[i][2] # emerg id\n",
    "    x_ids = df.loc[i][3] # node id\n",
    "    x1 = df.loc[i][4]\n",
    "    x2 = df.loc[i][5]\n",
    "    if xgps_all.get(x_ids) == None:\n",
    "        gps_radius = 1994.737/(997.368**float(df.loc[i][11]))#worst : 1000, best : 2m\n",
    "        #gps_radius = 180/(75**float(df.loc[i][11]))\n",
    "        #gps_radius = 1/(1**float(df.loc[i][11]))\n",
    "        angle = 0.01*random.randint(0,600)\n",
    "        #gps_radius=0\n",
    "        x_gps = gps_radius*np.cos(angle)+x1\n",
    "        y_gps = gps_radius*np.sin(angle)+x2\n",
    "        xgps_all[x_ids] = x_gps  \n",
    "        e_radius = Interval(0,0.1)#distance based error\n",
    "        if ygps_all.get(x_ids) == None:\n",
    "            ygps_all[x_ids] = y_gps \n",
    "    #print('angle',angle,np.cos(angle),np.sin(angle),gps_radius,x1,x2,x_gps,y_gps)\n",
    "    #e_g = Interval(random.uniform(-(50+gps_radius),-gps_radius),random.uniform(gps_radius,gps_radius+50))\n",
    "    if (outdoor_los==True):\n",
    "        e_g = Interval(random.randint(-100,-25),random.randint(25,100))\n",
    "    elif (outdoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-500,-100),random.randint(100,500))\n",
    "    elif (indoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-1000,0),random.randint(0,1000))\n",
    "    #g1 = Interval(xgps_all[x_ids]+e_g)\n",
    "    #g2 = Interval(ygps_all[x_ids]+e_g)\n",
    "    g1 = Interval(xgps_all[x_ids])\n",
    "    g2 = Interval(ygps_all[x_ids])\n",
    "    eudist_xtruth = (x1,x2)\n",
    "    eudist_est = (g1.mid(),g2.mid())\n",
    "    eudist =  distance.euclidean(eudist_xtruth,eudist_est)\n",
    "    xy_gps =IntervalVector([g1,g2])#gps locations of nodes \n",
    "    all_gps_radius[x_ids]= Interval(eudist+e_g)\n",
    "    if all_x_gps.get(x_ids) == None:\n",
    "        all_x_gps[x_ids]=xy_gps#estimated locations of nodes  #estimated locations of nodes \n",
    "        x11 = all_x_gps[x_ids][0].mid()\n",
    "        x22 = all_x_gps[x_ids][1].mid()\n",
    "        if (all_x_gps[x_ids][0].is_empty()):\n",
    "            print('yes empty',x_ids,all_x_gps[x_ids][0])\n",
    "        heading_gps = (math.pi)/3.14*math.atan2(x2,x1)\n",
    "        if (heading_gps<0):\n",
    "          heading_gps = heading_gps+2*math.pi\n",
    "        e_h = Interval(heading_gps).inflate(0.01)\n",
    "        node_heading[x_ids] = e_h\n",
    "        gps_theta =  (math.pi)/3.14*math.atan2(x22-x2,x11-x1)\n",
    "        if (gps_theta<0):\n",
    "          gps_theta = gps_theta+2*math.pi\n",
    "        all_x_gpstheta[x_ids] = gps_theta\n",
    "\n",
    "# =================== 0. Definitions ==================================================================================================================================================\n",
    "def loc_area(x1,y1,x2,y2):\n",
    "    area= abs(x1-x2)*abs(y1-y2)\n",
    "    return area \n",
    "\n",
    "def mean_square_error(act_arr,est_arr):#vectors: estimated x1 y1 \n",
    "  dst   = 0 \n",
    "  for i in range (0, len(act_arr)):\n",
    "      a = act_arr[i]\n",
    "      b = est_arr[i]\n",
    "      dst += distance.euclidean(a,b)#convert to meters\n",
    "  avg_error = math.sqrt(dst/len(act_arr))\n",
    "  return avg_error\n",
    "\n",
    "def theta_limits(theta_truth,outdoor_los,outdoor_nlos,indoor_nlos,heading):\n",
    "    if (outdoor_los==True):\n",
    "        max_error_angle = math.pi/10\n",
    "    elif (outdoor_nlos==True):\n",
    "        max_error_angle = math.pi/8\n",
    "    elif (indoor_nlos==True):\n",
    "        max_error_angle = math.pi/6#indoor nlos 30 degrees to one side\n",
    "\n",
    "    #theta_truth=math.atan2(deltay,deltax)    \n",
    "    if (theta_truth<0):\n",
    "        theta_truth=theta_truth+2*math.pi # form anticlockwise angle \n",
    "    #observed angle by bench\n",
    "    #a_obs=theta_truth + random.random()*2*max_error_angle-max_error_angle+heading\n",
    "    #random.random()*2*max_error_angle-max_error_angle#30 degree variation\n",
    "    a_obs = theta_truth +np.random.uniform(0, max_error_angle)\n",
    "    amin=a_obs-(max_error_angle)#theta error opening \n",
    "    amax=a_obs+(max_error_angle)\n",
    "    return [Interval(amin,amax)]\n",
    "\n",
    "def theta_limitsv2(theta_truth,outdoor_los,outdoor_nlos,indoor_nlos):\n",
    "    if (outdoor_los==True):\n",
    "        max_error_angle = math.pi/10\n",
    "    elif (outdoor_nlos==True):\n",
    "        max_error_angle = math.pi/8\n",
    "    elif (indoor_nlos==True):\n",
    "        max_error_angle = math.pi/6#indoor nlos 30 degrees to one side\n",
    "\n",
    "    #theta_truth=math.atan2(deltay,deltax)    \n",
    "    #if (theta_truth<0):\n",
    "        #theta_truth=theta_truth+2*math.pi # form anticlockwise angle \n",
    "    #observed angle by bench\n",
    "    a_obs=theta_truth + random.random()*2*max_error_angle-max_error_angle#30 degree variation\n",
    "\n",
    "    amin=a_obs-(max_error_angle)#theta error opening \n",
    "    amax=a_obs+(max_error_angle)\n",
    "\n",
    "    return [Interval(amin,amax)]\n",
    "\n",
    "def error_range(range,outdoor_los,outdoor_nlos,indoor_nlos):\n",
    "    if (outdoor_los==True):\n",
    "        e_y = range*Interval(random.randint(-200,-50),random.randint(50,200))\n",
    "    elif (outdoor_nlos==True):\n",
    "        e_y = range*Interval(random.randint(-1500,-200),random.randint(200,1500))\n",
    "    elif (indoor_nlos==True):\n",
    "        e_y = 0.5*range*Interval(random.randint(-2000,-0),random.randint(0,2000))\n",
    "    return e_y\n",
    "\n",
    "def error_range_toa(range,outdoor_los,outdoor_nlos,indoor_nlos):\n",
    "    if (outdoor_los==True):\n",
    "        e_y = range*Interval(random.randint(-150,-30),random.randint(30,150))\n",
    "    elif (outdoor_nlos==True):\n",
    "        e_y = range*Interval(random.randint(-1250,-150),random.randint(150,1250))\n",
    "    elif (indoor_nlos==True):\n",
    "        e_y = 0.5*range*Interval(random.randint(-200,0),random.randint(0,200))\n",
    "    return e_y\n",
    "\n",
    "def error_gps(gpsestimate,outdoor_los,outdoor_nlos,indoor_nlos):\n",
    "    if (outdoor_los==True):\n",
    "        e_g = Interval(random.randint(-100,-25),random.randint(25,100))\n",
    "    elif (outdoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-500,-100),random.randint(100,500))\n",
    "    elif (indoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-1000,0),random.randint(0,1000))\n",
    "    return e_g\n",
    "\n",
    "def toa_with_uncertainities(xtruth,b):\n",
    "    v_obstoa = DataLoader.generate_static_observations(xtruth,b, False)\n",
    "    for tt in v_obstoa: # for each gps:\n",
    "        e_toa = error_range_toa(tt[0],outdoor_los,outdoor_nlos,indoor_nlos)\n",
    "        tt[0]= tt[0]+e_toa#range\n",
    "        tt[1].inflate(0.0) # bearing\n",
    "    return v_obstoa\n",
    "    \n",
    "def collect_data(j,emergarr,all_x_gps):\n",
    "    nodeid = df.loc[j][3]\n",
    "    if (nodeid in nodearr):#nodearr has all unique nodes\n",
    "        tuy=0\n",
    "    else:    \n",
    "        nodearr.append(int(nodeid))\n",
    "    emerg_ids = df.loc[j][2] # emerg id\n",
    "    if (emerg_ids in emergarr):#nodearr has all unique nodes\n",
    "        tuy=0\n",
    "    else:    \n",
    "        emergarr.append(emerg_ids)\n",
    "    x1 = df.loc[j][4]\n",
    "    x2 = df.loc[j][5]\n",
    "    x_truth= [df.loc[j][4],df.loc[j][5],math.atan2(x2,x1)] # (x,y,heading)#n1\n",
    "    e_bs = Interval(random.randint(-2000,-1200),random.randint(1200,2000))\n",
    "    x11 = Interval(x1+e_bs)\n",
    "    x22 = Interval(x2+e_bs)\n",
    "    ntruth[int(nodeid)] = [IntervalVector([x11,x22])]\n",
    "    e_aoa = Interval(random.randint(-1000000000000,-0),random.randint(0,1000000000000))#uncertain error\n",
    "    xaoa = Interval(x1+e_aoa)\n",
    "    yaoa = Interval(x2+e_aoa)\n",
    "    ntruthaoa[int(nodeid)]= [IntervalVector([xaoa,yaoa])]\n",
    "    if (node_xtruth.get(nodeid)== None):#nodeid, truth location \n",
    "        node_xtruth[nodeid] = x_truth\n",
    "\n",
    "    if (node_benchids.get(str(int(nodeid)))== None):\n",
    "        node_benchids[str(int(nodeid))] = str(df.loc[j][6])\n",
    "    else:\n",
    "        lst0 = node_benchids[str(int(nodeid))]\n",
    "        lst = (df.loc[j][6])\n",
    "        node_benchids[str(int(nodeid))] = str(lst0)+';'+str(lst)\n",
    "  \n",
    "    #benchmark locations, b\n",
    "    benchmark1_truth =  [df.loc[j][7],df.loc[j][8]] #benchmark locations\n",
    "    benchids = node_benchids[str(int(nodeid))].split(';')\n",
    "    #yy =benchids[len(benchids)-1] #last bench id\n",
    "    yy = str(df.loc[j][6])\n",
    "    if (outdoor_los==True):\n",
    "        e_g = Interval(random.randint(-1200,-700),random.randint(700,1200))\n",
    "    elif (outdoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-2700,-1200),random.randint(1200,2700))\n",
    "    elif (indoor_nlos==True):\n",
    "        e_g = Interval(random.randint(-3500,-1200),random.randint(1200,3500))\n",
    "    ####################################################################################################\n",
    "    bench1 = float(benchmark1_truth[0])\n",
    "    bench2 = float(benchmark1_truth[1]) \n",
    "    bench_heading[yy] = Interval(math.atan2(float(benchmark1_truth[1]),float(benchmark1_truth[0]))).inflate(0.01)#heading measurement with 0.01 error\n",
    "    #btruth[yy] = [float(benchmark1_truth[0]),float(benchmark1_truth[1]),bench_heading[yy].mid()]\n",
    "    btruth[yy]= [bench1, bench2,math.atan2(bench2,bench1)] # (x,y,heading)#n1\n",
    "    ####################################################################################################\n",
    "    if (yy==\"gNB\"):\n",
    "        bench1 = float(benchmark1_truth[0])\n",
    "        bench2 = float(benchmark1_truth[1])\n",
    "        e_bs = Interval(random.randint(-1,0),random.randint(0,1))\n",
    "        b1 = Interval(bench1+e_bs)\n",
    "        b2 = Interval(bench2+e_bs)#estimated locations of bench nodes \n",
    "        toa = float(df.loc[j][13]) #time of arrival\n",
    "        node_incoverage[nodeid] = True\n",
    "    elif yy in all_x_gps:\n",
    "        b1 = all_x_gps[yy][0]#estimated locations of bench nodes \n",
    "        b2 = all_x_gps[yy][1]#estimated locations of bench nodes \n",
    "    else:\n",
    "        bench1 = float(benchmark1_truth[0])\n",
    "        bench2 = float(benchmark1_truth[1])\n",
    "        #e_bs = Interval(random.randint(-3000,-1000),random.randint(1000,3000))\n",
    "        e_bs = Interval(random.randint(-1,0),random.randint(0,1))\n",
    "        b1 = Interval(bench1+e_g)\n",
    "        b2 = Interval(bench2+e_g)#estimated locations of bench nodes \n",
    "    benchmark_est = [IntervalVector([b1,b2])]\n",
    "\n",
    "    if (node_benchtruth.get(int(nodeid))== None):#nodeid, benchtruth location \n",
    "        node_benchtruth[int(nodeid)] = (benchmark_est)\n",
    "    else:\n",
    "        lst0 = node_benchtruth[int(nodeid)]\n",
    "        lst = benchmark_est\n",
    "        node_benchtruth[int(nodeid)] = (lst0+lst)   \n",
    "    return node_benchids,node_benchtruth,node_heading,emergarr\n",
    "\n",
    "\n",
    "def forward_tracking(node_ids,node_benchids,node_benchtruth,node_heading,time,emergarr,all_x_gps,all_gps_radius,all_x_gpstheta):\n",
    "    for iter in node_ids:#for each node recorded till now      \n",
    "            id =iter\n",
    "            b = node_benchtruth[iter]#data stored in the order of nbnode index\n",
    "            gps = all_x_gps[iter]   \n",
    "            gps_radius = all_gps_radius[iter]\n",
    "            #$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "            benchids = node_benchids[str(iter)].split(';')\n",
    "            if (b[0].is_empty()):\n",
    "                yyy= 0\n",
    "                print('vobs empty')\n",
    "            else:\n",
    "                cn = ContractorNetwork() \n",
    "                \n",
    "                for i in range (0,len(b)): # for each range and bearing measurement\n",
    "                      p = cn.create_dom(IntervalVector(2))     \n",
    "                      alpha = cn.create_dom(Interval())\n",
    "                      d = cn.create_dom(IntervalVector(2))\n",
    "                      yy = benchids[i]\n",
    "                      v_obs = DataLoader.generate_static_observations(btruth[yy],ntruth[iter],False)#generate actual range, bearing values\n",
    "                      if (node_incoverage.get(iter)==None):#out of coverage                         \n",
    "                          #print(v_obs)\n",
    "                          #print(iter, yy,v_obs)\n",
    "                          for rg in v_obs: # for observation type:range#shifting the actual range to a point within interval of error\n",
    "                            k = random.choice([-1, 1])*random.randrange(1000,2000)\n",
    "                            e_y = 1*rg[0]*Interval(k,k)#error depends on the distance by 0.01%\n",
    "                            rg[0] = rg[0]+e_y#randomly choose whether it shift in positive direction or negative direction\n",
    "                          # Adding uncertainties on the measurements\n",
    "                          for hh in v_obs: # for each observation:\n",
    "                            e_y = 1*hh[0]*Interval(random.randint(-2000,-0),random.randint(0,2000))\n",
    "                            hh[0]= hh[0]+e_y#range\n",
    "                            hh[1].inflate(0.0) # bearing \n",
    "                          cn.add(ctc.dist, [p, b[i], v_obs[0][0]])# Distance constraint: relation between the state at t_i and the ith beacon position                         \n",
    "                cn.add(ctc_circle,[p[0],p[1],gps[0],gps[1],gps_radius])         \n",
    "                contraction_dt = cn.contract()#csp solving time set to 2 sec\n",
    "                sol.append(p)\n",
    "                #distribute 50 points uniformly in the rectangle created by p\n",
    "                mcl_points = []\n",
    "                post_mcl_points =[]\n",
    "                filtered_mcl_points=[]\n",
    "                benchids = node_benchids[str(iter)].split(';')\n",
    "                for i in range(0,50):#50 partcles considered\n",
    "                  X = np.random.uniform(p[0][0], p[0][1]);\n",
    "                  Y = np.random.uniform(p[1][0], p[1][1]);\n",
    "                  mcl_points.append((X,Y))\n",
    "                dst   = 0 \n",
    "                for ii in range (0, len(mcl_points)):\n",
    "                    for jj in range (0,len(b)):\n",
    "                      anchor_pos = (b[jj][0].mid(),b[jj][1].mid())\n",
    "                      #print('mcl point ii',mcl_points[ii])\n",
    "                      dst= distance.euclidean(mcl_points[ii],anchor_pos)#convert to meters\n",
    "                      \n",
    "                      yy = benchids[jj]\n",
    "                      v_obs = DataLoader.generate_static_observations(btruth[yy],ntruth[iter],False)\n",
    "                      ben_radius = v_obs[0][0].mid()\n",
    "                      if (v_obs[0][0].mid()> dst):#if rssi dist < distance between the mcl point and anchor position remove that point\n",
    "                        post_mcl_points.append(mcl_points[ii])\n",
    "                #print(filtered_mcl_points)\n",
    "                import collections\n",
    "                ctr = collections.Counter(post_mcl_points)\n",
    "                #print(ctr)\n",
    "                #filtering the partcles that satisfy the rssi constraints\n",
    "                for kk in range(len(ctr)):\n",
    "                    if (ctr[post_mcl_points[kk]]==len(b)):\n",
    "                        filtered_mcl_points.append(post_mcl_points[kk])\n",
    "                for ll in range(len(filtered_mcl_points)):\n",
    "                  averagex = np.average(filtered_mcl_points[ll][0])\n",
    "                  averagey = np.average(filtered_mcl_points[ll][1])\n",
    "                additional_complexity = 50+len(mcl_points)*len(b)+len(ctr)+len(filtered_mcl_points)\n",
    "                if (time_complexity.get(time) ==None):\n",
    "                    time_complexity[time] =additional_complexity+len(b)\n",
    "                    time_carr.append(float(time))\n",
    "                else:\n",
    "                    time_complexity[time] = len(b)+additional_complexity+time_complexity.get(time)\n",
    "                if (len(filtered_mcl_points)>0):\n",
    "                  mcl_p = (averagex,averagey)\n",
    "                  if (math.isnan(time)==False and time_contract.get(time)== None):\n",
    "                      time_contract[time] = contraction_dt#time taken to localize a device in this time\n",
    "                  elif (math.isnan(time)==False):\n",
    "                      time_contract[time] = contraction_dt+ time_contract.get(time)\n",
    "                  if iter in emergarr:#only emerg node ids\n",
    "                        x1 = node_xtruth[iter][0]\n",
    "                        x2 = node_xtruth[iter][1]\n",
    "                        all_pix_coor.append([x1,x2])\n",
    "                        all_est_coor.append([mcl_p])\n",
    "                        er = mean_square_error(all_pix_coor,all_est_coor)\n",
    "                        #if (er>20):\n",
    "                            #print(iter, [x1,x2],p[0].mid(),p[1].mid())\n",
    "                        all_er_mean.append(er)#MSE in m^2\n",
    "                        key = str(iter)+';'+str(time)\n",
    "                        id_time_error[key] = er\n",
    "                        id_time_arr.append(key)\n",
    "                        id_time_cdt[key] = contraction_dt\n",
    "                        id_time_est_coord[key] = (mcl_p)\n",
    "                        if (id_error.get(iter)== None):\n",
    "                            id_error[iter] = er\n",
    "                            id_count[iter] = 1\n",
    "                            id_arr.append(iter)\n",
    "                        else:\n",
    "                            id_count[iter]= 1+id_count[iter]\n",
    "                            id_error[iter] = (er+id_error.get(iter))/id_count[iter]\n",
    "                        if (math.isnan(time)==False and time_error.get(time)== None):\n",
    "                            time_error[time] = er#only emerg device\n",
    "                            error_count[time]= 1\n",
    "                            time_arr.append(time)#use to identify the time\n",
    "                            err_minmax[time] = str(er)\n",
    "                        elif (math.isnan(time)==False):\n",
    "                            time_error[time] = er+time_error.get(time)#only emerg device\n",
    "                            error_count[time]= 1+error_count.get(time)\n",
    "                            err_minmax[time] = err_minmax.get(time)+';'+str(er)\n",
    "                        if (id_contract.get(iter)== None):\n",
    "                            id_contract[iter] = contraction_dt\n",
    "                        else:\n",
    "                            id_contract[iter] = contraction_dt+ id_contract.get(iter)                               \n",
    "    return sol_ids\n",
    "\n",
    "# =========== Defining contractors to deal with equations ==================================================================================================================================\n",
    "# We use the predefined contractor ctc.dist, no need to build it\n",
    "ctc_plus = CtcFunction(Function(\"a\", \"b\", \"c\", \"a+b-c\")) # a+b=c\n",
    "ctc_minus = CtcFunction(Function(\"a\", \"b\", \"c\", \"a-b-c\")) # a-b=c#a=b\n",
    "ctc_polarx = CtcFunction(Function(\"a\", \"b\", \"c\",\"d\",\"a-b-c*cos(d)\"))\n",
    "ctc_polary = CtcFunction(Function(\"a\", \"b\", \"c\",\"d\",\"a-b-c*sin(d)\"))\n",
    "ctc_dist = CtcFunction(Function(\"x[2]\", \"b[2]\", \"y\",\"sqrt((x[0]-b[0])^2+(x[1]-b[1])^2)-y\"))\n",
    "ctc_polar = CtcPolar()\n",
    "ctc_circle = CtcFunction(Function(\"px\", \"py\", \"xc\",\"yc\",\"r\",\"(px-xc)^2+(py-yc)^2-r^2\"))\n",
    "ctc_taninverse =CtcFunction(Function(\"x[2]\", \"b[2]\",\"h\",\"t\",\"atan2(x[1]-b[1],x[0]-b[0])-h-t\"))\n",
    "ctc_sinlimits = CtcFunction(Function(\"x[2]\", \"b[2]\",\"t\",\"(x[1]-b[1])/((x[0]-b[0])^2+(x[1]-b[1])^2)-t\"))\n",
    "# =========== Contractor network ===========================================================================================================================================================\n",
    "cn = ContractorNetwork()\n",
    "# =========== Time constraints =============================================================================================================================================================\n",
    "thirty_min_lb = 0 \n",
    "thirty_min_ub = 1800 \n",
    "jj = 1#index where data starts\n",
    "t_ub = 120#update upper bound#time interval of csp problem update(sec)\n",
    "sliding_count = 0\n",
    "next_tub_stop=t_ub\n",
    "\n",
    "past_data_refresh=False\n",
    "while thirty_min_lb <= thirty_min_ub:#while now is below the upper bound of time domain\n",
    "    time_error_count =0\n",
    "    if float(df.loc[jj][13])< next_tub_stop and float(df.loc[jj][13])<= t_ub:  \n",
    "         node_benchids,node_benchtruth,node_heading,emergarr =collect_data(jj,emergarr,all_x_gps)#collect past window data\n",
    "         if (jj<rows):  \n",
    "            jj+=1# jj: global node index \n",
    "    else: \n",
    "         time_error_count =0\n",
    "         if (float(df.loc[jj][13])>thirty_min_ub and past_data_refresh==True):#if time is above 1800 and current node considered>last refreshed node\n",
    "            print('here 2')\n",
    "            sol_with_ids = forward_tracking(nodearr,node_benchids,node_benchtruth,node_heading,df.loc[jj][13],emergarr,all_x_gps,all_gps_radius,all_x_gpstheta)\n",
    "         elif (past_data_refresh==False):#if time is between 0 and 1800 and past data not refreshed\n",
    "            print('here 1')\n",
    "            sol_with_ids = forward_tracking(nodearr,node_benchids,node_benchtruth,node_heading,df.loc[jj][13],emergarr,all_x_gps,all_gps_radius,all_x_gpstheta)\n",
    "         if (float(df.loc[jj][13])>thirty_min_ub):           \n",
    "            past_data_refresh=True\n",
    "            #pp ==jj#last node index before refreshing\n",
    "            thirty_min_ub+=120#sliding window by 120\n",
    "            thirty_min_lb+=120\n",
    "            sliding_count +=1\n",
    "            jj =1\n",
    "            while (float(df.loc[jj][13])<thirty_min_lb ):    \n",
    "                jj+=1  #setting starting data row related to 30 min lower bound\n",
    "            t_ub = (sliding_count+1)*120#starting t_ub\n",
    "            past_tub_stop = t_ub#past localization stop tub\n",
    "            next_tub_stop=past_tub_stop +120\n",
    "            #clear previous input arr\n",
    "            node_benchids = {}#data refresh\n",
    "            node_benchtruth = {}\n",
    "            node_y = {}\n",
    "            node_theta = {}\n",
    "            node_ids = {}\n",
    "            nodearr = []\n",
    "            emergarr =[]\n",
    "            nodearr = []\n",
    "         while (float(df.loc[jj][13])> t_ub):    \n",
    "            t_ub+=120  \n",
    "            next_tub_stop+=120\n",
    "         print('routinely update',jj) \n",
    "         #node_benchids = {}#data refresh\n",
    "         #node_benchtruth = {}\n",
    "         #node_y = {}\n",
    "         #node_theta = {}\n",
    "         #node_ids = {}\n",
    "         #nodearr = []\n",
    "    if (jj==rows):#last data received from simulation\n",
    "         break  \n",
    "\n",
    "print(all_er_mean)\n",
    "\n",
    "# =========== Export data ===============================================================================================================================================================\n",
    "import xlwt\n",
    "list1 = id_contract\n",
    "list2 = all_er_mean\n",
    "book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "\n",
    "i =1\n",
    "sheet1 = book.add_sheet(\"Sheet 1\")  \n",
    "for n in range(0,len(id_error)):\n",
    "    i = i+1#row number\n",
    "    gg = id_arr[n]\n",
    "    h  = id_error[int(gg)]\n",
    "    sheet1.write(i, 0, int(gg))\n",
    "    sheet1.write(i, 1, h)\n",
    "\n",
    "k= 1\n",
    "sheet2 = book.add_sheet(\"Sheet 2\")    \n",
    "for n in range(0,len(time_error)):\n",
    "    k = k+1#row number\n",
    "    gg = time_arr[n]\n",
    "    h=time_contract[gg]\n",
    "    sheet2.write(k, 0, gg)\n",
    "    sheet2.write(k, 1, h)\n",
    "\n",
    "u = 1\n",
    "sheet3 = book.add_sheet(\"Sheet 3\")    \n",
    "for n in range(0,len(time_error)):\n",
    "    u = u+1#row number\n",
    "    gg = time_arr[n]\n",
    "    h=time_error[gg]\n",
    "    m = error_count[gg]\n",
    "    dg = h/m\n",
    "    sheet3.write(u, 0, gg)\n",
    "    sheet3.write(u, 1, h)\n",
    "    sheet3.write(u, 2, dg)\n",
    "\n",
    "y = 1\n",
    "sheet4 = book.add_sheet(\"Sheet 4\")    \n",
    "for n in range(0,len(time_complexity)):\n",
    "    y = y+1#row number\n",
    "    gg = time_carr[n]\n",
    "    h=time_complexity[gg]\n",
    "    sheet4.write(y, 0, gg)\n",
    "    sheet4.write(y, 1, h)\n",
    "\n",
    "vu = 1\n",
    "sheet6 = book.add_sheet(\"Sheet 6\")    \n",
    "for n in range(0,len(id_time_error)):\n",
    "    vu = vu+1#row number\n",
    "    gg = id_time_arr[n]\n",
    "    h=id_time_error[gg]\n",
    "    sheet6.write(vu, 0, gg)\n",
    "    sheet6.write(vu, 1, h)\n",
    "\n",
    "ve = 1\n",
    "sheet7 = book.add_sheet(\"Sheet 7\")    \n",
    "for n in range(0,len(err_minmax)):\n",
    "    ve = ve+1#row number\n",
    "    gg = time_arr[n]\n",
    "    h=err_minmax[gg]\n",
    "    #split h by ;\n",
    "    x = h.split(';')\n",
    "    m = error_count[gg]\n",
    "    #nb rows = error count\n",
    "    for pl in range(0,m):\n",
    "        sheet7.write(pl, ve, x[pl])\n",
    "    sheet7.write(m+1, ve, gg)\n",
    "\n",
    "kk= 1\n",
    "sheet8 = book.add_sheet(\"Sheet 8\")    \n",
    "for n in range(0,len(id_contract)):\n",
    "    kk = kk+1#row number\n",
    "    gg = id_arr[n]\n",
    "    h  = id_contract[gg]\n",
    "    sheet8.write(kk, 0, int(gg))\n",
    "    sheet8.write(kk, 1, h)\n",
    "\n",
    "vuu = 1\n",
    "sheet9 = book.add_sheet(\"Sheet 9\")    \n",
    "for n in range(0,len(id_time_cdt)):\n",
    "    vuu = vuu+1#row number\n",
    "    gg = id_time_arr[n]\n",
    "    h=id_time_cdt[gg]\n",
    "    sheet9.write(vuu, 0, gg)\n",
    "    sheet9.write(vuu, 1, h)\n",
    "\n",
    "vt = 1\n",
    "sheet10 = book.add_sheet(\"Sheet 10\")    \n",
    "for n in range(0,len(id_time_est_coord)):\n",
    "    vt = vt+1#row number\n",
    "    gg = id_time_arr[n]\n",
    "    x = gg.split(';')\n",
    "    h=id_time_est_coord[gg]\n",
    "    sheet10.write(vt, 0, gg)\n",
    "    sheet10.write(vt, 1,str(h))\n",
    "    sheet10.write(vt, 2, str(node_xtruth[float(x[0])]))\n",
    "\n",
    "book.save(\"montecarlo 5gnbs loc error.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a294dfc-3227-4972-ad49-fbafbc592b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
